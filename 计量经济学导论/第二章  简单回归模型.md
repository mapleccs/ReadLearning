## 第二章  简单回归模型

简单回归模型可以用来研究两个变量之间的关系。出于我们将会看到的原因，简单回归模型作为实证分析的一般工具还存在着局限性，不过有时把它作为一个实证工具也是合适的。对于我们接下来几章要学习的多元回归模型来说，学会解释简单回归模型无疑也是很好的练习。

### 2.1  简单回归模型的定义

我们运用的许多计量经济学分析都是从如下假设开始的：$y$ 和 $x$ 是两个代表总体的变量，我们感兴趣的是＂用 $x$ 来解释 $y$＂，或＂研究 $x$ 变化时 $y$ 怎么变＂。我们在第1章中讨论了一些例子，包括：$y$ 是大豆的产出，$x$ 是肥料的用量；$y$ 是每小时的工资，$x$ 是受教育的年数；$y$ 是社区的犯罪率，$x$ 是警察的数量。

在写出一个用 $x$ 解释 $y$ 的模型时，我们一定会面临三个问题。第一，既然两个变量之间没有一个确切的关系，那么我们该如何考虑其他因素对 $y$ 的影响？第二， $y$ 和 $x$ 的函数关系是怎样的？第三，如何确定我们刻画的是在其他条件不变的情况下 $y$ 和 $x$ 的关系（如果这是我们想要的目标）？

我们可以通过写出一个 $y$ 关于 $x$ 的方程来解决这些困惑。一个简单的方程是：

$$
y=\beta_0+\beta_1 x+u
$$


假定方程（1）在我们所关注的总体中成立，它便定义了一个简单线性回归模型（simple linear regression model）。由于它将 $x$ 和 $y$ 两个变量联系了起来，因此也称作两变量或者双变量线性回归模型。我们现在来讨论方程（1）中每个量的含义。［＂回归＂这个词的起源对于大部分现代计量经济学的应用来说并非特别重要，所以我们在此不予讨论。可参见施蒂格勒（Stigler，1986）对回归分析充满魅力的历史所做的介绍。］

在方程（1）中，变量 $y$ 和 $x$ 有许多可以交互使用的不同名称。比如：$y$ 被称为因变量（dependent variable），被解释变量（explained variable），响应变量 （response variable），被预测变量（predicted variable）或者回归子（regressand）。

$x$ 则被称为自变量（independent variable），解释变量（explanatory variable），控制变量（control variable），预测变量（predictor variable）或者回归元（regressor）。 $[x$ 还被称为协变量（covariate）。］＂因变量＂和＂自变量＂两个词在计量经济学中使用较多，但要注意这里所说的＂自变＂（independent）与统计学概念里随机变量之间的独立有所不同（参见书末附录数学复习 B）。

＂被解释＂和＂解释＂变量这两个词可能是最具描述性的。＂响应＂和＂控制＂在实验性科学中被运用得最多，其中 $x$ 变量是被实验者控制的。我们不使用＂被预测变量＂和＂预测变量＂这样的字眼，尽管有时候在一些纯粹预测而非因果推断的应用研究中会看到它们。在下表中，我们总结了简单回归中的术语。

| $Y$        | $X$      |
| ---------- | -------- |
| 因变量     | 自变量   |
| 被解释变量 | 解释变量 |
| 响应变量   | 控制变量 |
| 被预测变量 | 预测变量 |
| 回归子     | 回归元   |

变量 $u$ 被称为关系式中的误差项（error term）或者扰动项（disturbance），它代表除 $x$ 以外其他影响 $y$ 的因素。简单回归分析有效地把除 $x$ 之外其他所有影响 $y$ 的因素都看成是没有被观察到的因素。你也可以把 $u$ 看作是＂没有被观察到＂的因素。

方程（1）还解决了 $y$ 和 $x$ 的函数关系的问题。若 $u$ 中的因素保持不变，则 $u$ 的变化为 0 ，即 $\Delta u=0$ ，那么 $x$ 对 $y$ 的影响是线性的：
$$
若\Delta u=0，则\Delta y=\beta_1 \Delta_x
$$

因此，$y$ 的变化就是 $\beta_1$ 乘以 $x$ 的变化。这就是说，保持 $u$ 中的因素不变，$\beta_1$ 就是 $y$ 和 $x$ 的关系式中的斜率参数（slope parameter）；在应用经济学中，这是人们最感兴趣的地方。截距参数（intercept parameter）$\beta_0$ 有时被称作常数项，虽然它很少被当作分析的核心，但也是有作用的。

（1）式的线性形式意味着：不管 $x$ 的初始值为多少，它的任何一单位变化对 $y$ 的影响都是相同的。这对许多经济应用来说是不现实的。举例来说，在工资一教育的例子中，我们或许还要考虑到回报是递增的，即后一年的教育对工资的影响比前一年的教育更大。我们将在 2.4 节中研究如何考虑这种可能性。

我们要解决的最困难的问题是：模型（1）是否真的能让我们得到关于$x$如何在其他因素不变的情况下影响 $y$ 的结论？我们从方程（2）中看到，保持 （ $u$ 中）所有其他因素不变，$\beta_1$ 确实能够度量 $x$ 对 $y$ 的影响。但我们对这个因果问题的讨论可以就此结束吗？非常不幸，还不行。那么一般来说，我们怎么能在忽略所有其他因素，同时又控制所有其他因素不变的情况下，得到 $x$ 对 $y$ 的影响？

2.5 节将说明，只有当我们约束无法观测的 $u$ 与解释变量 $x$ 之间的关系时，才能从一个随机数据样本中获得 $\beta_0$ 和 $\beta_1$ 的可靠估计量。没有这样一个约束，我们就不能估计出在其他条件不变下的 $\beta_1$ 。因为 $u$ 和 $x$ 都是随机变量，所以我们需要一个基于概率的概念。

在我们陈述 $x$ 和 $u$ 的关系这个关键假设之前，我们总能先对 $u$ 做一个假设。只要方程中包含截距项 $\beta_0$ ，那么假设总体中 $u$ 的平均值为 0 就不会使我们损失信息。用数学形式表示就是：

$$
\mathrm{E}(u)=0
$$

假定（3）并没有提到 $u$ 和 $x$ 的关系，只是简单地陈述了总体中无法观测的因素的分布情况。用前面的例子来说明，我们可以看到，假定（3）的约束性不是很强。在例 2.1 中，我们把诸如土地质量这种对大豆收成有影响而又观测不到的因素进行标准化，使其在所有耕地总体中的平均值为零，这对结果不会有影响。同样的结论对例 2.2 中无法观测的因素也是正确的。为了不失一般性，我们可以假定在所有工人构成的总体中，诸如平均能力等因素的值均为 0 。如果你还不信，试着做一下习题 2，你就会发现，我们总能够通过重新定义方程（1）中的截距使得方程（3）成立。

我们现在来讨论关于 $u$ 和 $x$ 关系的重要假设。度量两个随机变量之间关系的个自然指标是相关系数。若 $u$ 和 $x$ 不相关，则作为随机变量，它们就没有线性关系。假定 $u$ 和 $x$ 不相关，这对定义方程（1）中 $u$ 和 $x$ 无关有很大作用。不过这种作用仍是有限的，因为相关关系只度量了 $u$ 和 $x$ 之间的线性相关性。相关关系有一种违背直觉的性质：虽然 $u$ 与 $x$ 不相关，但可能与 $x$ 的函数比如 $x^2$ 相关。对于大部分回归而言，这种可能性是不能被接受的，因为它会在我们解释模型和推导统计性质的时候带来问题。一种更好的方法是对给定 $x$ 时 $u$ 的期望值做出假定。

因为 $u$ 和 $x$ 是随机变量，所以我们能够在任意一个给定的 $x$ 值下定义 $u$ 的条件分布。具体地说，对于任意一个 $x$ 值，我们都能够在 $x$ 值所描述的总体剖面上求出 $u$ 的期望（或平均）值。关键的假设是，假定 $u$ 的平均值不依赖于 $x$ 的值。我们可以把它写作：

$$
\mathrm{E}(u \mid x)=\mathrm{E}(u)
$$


方程（4）说的是，如果根据 $x$ 值的不同把总体划分成若干部分，每个部分中无法观测的因素都具有相同的平均值，而且这个相同的平均值必然等于整个总体中 $u$ 的平均值。当方程（4）成立时，我们就说 $u$ 的均值独立（mean independent）于 $x$ 。（当然，在基础概率和统计学中，一个常用的假设是 $u$ 和 $x$ 完全独立，这个假设就暗含了均值独立性。）当我们把均值独立性与假设（3）相结合时，便得到**零条件均值假定**（zero conditional mean assumption）： $\mathrm{E}(u \mid x)=0$ 。关键是我们要记住方程（4）是一个有重要影响的假定；而假定（3）只是定义了截距 $\beta_0$ 。

让我们看一下在关于工资的例子中，方程（4）蕴含着什么。为简化讨论，假定 $u$ 代表工人天生的能力，那么方程（4）就要求无论受教育程度如何，工人能力的平均水平都相同。例如，若 $\mathrm{E}(abil\mid 8)$表示所有受过 8 年教育的工人的平均能力， $\mathrm{E}(a b i l \mid 16)$ 表示所有受过 16 年教育的工人的平均能力，那么方程（4）就意味着二者相等。事实上，无论受教育程度怎样，所有工人都具有相同的平均能力。如果我们认为平均能力是随着受教育程度的增加而递增的，那么方程（4）就是错的。（如果通常能力越高的人选择接受越多的教育，那么这种情形就会出现。）由于我们观察不到天生的能力，所以我们无法确知不同受教育程度的人的平均能力是否一样，但这是我们在简单回归分析之前必须提出的问题。

在施肥的例子中，如果施肥量与该地区的其他条件没有关系，那么方程（4）就能够成立：土地的平均质量不会依赖于施肥量。然而，如果更多的肥料被施用在更高质量的土地上，那么 $u$ 的期望值就会随着肥料的用量而改变，方程（4）也就不成立了。

零条件均值假定给出了 $\beta_1$ 的另一种有用的解释。给定 $x$ ，对方程（4）取条件期望，并利用 $\mathrm{E}(u \mid x)=0$ ，便得到：

$$
\mathrm{E}(y \mid x)=\beta_0+\beta_1 x
$$

方程（5）表明，总体回归函数（population regression function，PRF） $\mathrm{E}(y \mid x)$ 是 $x$ 的一个线性函数。线性意味着 $x$ 的 1 个单位的变化将使 $y$ 的期望值改变 $\beta_1$ 。

方程（5）告诉了我们 $y$ 的均值如何随着 $x$ 的变化而变化，它并不是说对于总体中的所有单位，$y$ 都等于 $\beta_0+\beta_1 x$ ，理解这一点很重要。比如，假设 $x$ 表示高中时的平均成绩，$y$ 表示大学时的平均成绩，而且我们正好知道 $\mathrm{E}(colGPA \mid hsGPA)=1.5+0.5 h s G P A$ 。［当然，实际上我们永远也不知道总体的截距和斜率，但为了理解方程（5）的性质，我们最好暂时假装我们知道。］这个平均成绩的方程告诉我们：对于给定高中平均成绩的所有学生而言，他们在大学阶段的平均成绩是什么状况。于是，假设 $h s G P A=3.6$ ，那么对所有以 $h s G P A=3.6$ 的成绩被大学录取的高中毕业生而言，colGPA 的平均水平是 $1.5+0.5 \times 3.6=3.3$ 。我们当然不是说所有 $h s G P A=3.6$ 的学生在大学的平均成绩都是 3.3 ，这明显是错误的。总体回归函数给出了不同 $x$ 值水平上 $y$ 的平均水平之间的关系。有些 $h s G P A=3.6$ 的学生在大学阶段的平均成绩高于 3.3 ，也有一些学生的大学平均成绩低于 3.3 。实际大学平均成绩是高于还是低于 3.3 取决于 $u$ 中无法观测的因素，甚至在 $h s G P A=3.6$的那部分学生中，这些因素也有所不同。

给定零条件均值假设 $\mathrm{E}(u \mid x)=0$ ，一个比较有用的做法是把方程（1）中的 $y$ 看成两个部分。一部分是表示 $\mathrm{E}(y \mid x)$ 的 $\beta_0+\beta_1 x$ ，这被称为系统部分的 $y$ ，即由 $x$ 解释的那一部分。另一部分是被称为非系统部分的 $u$ ，即不能由 $x$ 解释的那一部分。当我们在第 3 章引人不止一个解释变量时，我们还将讨论如何确定系统部分相对于非系统部分的大小。

在下一节，我们将在给定一个数据的随机样本的情况下，利用假设（3）和 （4）给出 $\beta_0$ 和 $\beta_1$ 的估计量。零条件均值假设对 2.5 节的统计分析也起到了关键作用。

